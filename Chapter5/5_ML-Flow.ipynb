{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_ML-Flow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsfqfIV8--z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データの用意\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df = sns.load_dataset(\"iris\")  # Irisのデータを取得\n",
        "df.iloc[0, 1] = np.NaN  # わざと欠損値を作る\n",
        "\n",
        "# データの表示\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzoDOedmNxma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pandas-profilingのパッケージをインストール\n",
        "!pip install pandas-profiling\n",
        "\n",
        "# データのprofileを作成\n",
        "import pandas_profiling as pdp\n",
        "from IPython.display import HTML\n",
        "\n",
        "profile = pdp.ProfileReport(df)\n",
        "profile.to_file(outputfile=\"profile.html\")\n",
        "HTML(filename='profile.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAxq41_gc6ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ノートブック上にグラフを描画するように設定\n",
        "%matplotlib inline\n",
        "\n",
        "# リスト5.2で欠損値にした箇所に対する計算エラーの警告を出力させないように設定\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "sns.boxplot(x='species', y='sepal_width', hue='species', data=df)\n",
        "sns.pairplot(df, hue='species')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw1Mb-Y0dihO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
        "\n",
        "# 将来的にデフォルト値が変更される警告が出力されないように設定\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# 1. 前処理------\n",
        "df = df.dropna()  # 欠損値のあるレコードを削除\n",
        "del df['petal_width']  # データチェックの結果からpetal_lengthと相関が強いpetal_widthは削除\n",
        "\n",
        "# カテゴリーデータであるspecies（種類）を数値データに変換\n",
        "df['species'] = df['species'].map(\n",
        "    {'setosa': 0, 'versicolor': 1, 'virginica': 2})\n",
        "\n",
        "# Numpyの変数を用意\n",
        "y = np.array(df['species'])\n",
        "X = np.array(df.iloc[:, 0:3])  # 0, 1, 2行目の3つを取得\n",
        "\n",
        "# 2. 入れ子式の交差検証法を行う用意\n",
        "# 2.1 outer loopの設定\n",
        "outer_loop = KFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "# 2.2 inner loopの設定\n",
        "inner_loop = KFold(n_splits=4, shuffle=True, random_state=0)\n",
        "\n",
        "# 2.3 パイプライン生成\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('logistic', LogisticRegression())])\n",
        "\n",
        "# 2.4 グリッドサーチの設定\n",
        "# 比較するハイパーパラメータ設定\n",
        "param_grid = {\n",
        "    'logistic__C': [1, 10, 100],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(\n",
        "    estimator=pipe, param_grid=param_grid, scoring='accuracy', cv=inner_loop)\n",
        "\n",
        "# 3. 学習\n",
        "val_result = np.zeros((5, 3))  # outer_loop数×ハイパーパラメータの種類\n",
        "ol_index = 0  # outer_loopのindex\n",
        "\n",
        "# outer loop\n",
        "for train_val_index, test_index in outer_loop.split(X):\n",
        "    X_train_val, X_test = X[train_val_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_val_index], y[test_index]\n",
        "\n",
        "    # inner loop\n",
        "    gs.fit(X_train_val, y_train_val)  # trainで学習し、valで評価\n",
        "    val_result[ol_index] = gs.cv_results_[\"mean_test_score\"]\n",
        "\n",
        "    print(\" outer loopの結果その{}：{}\".format(ol_index+1,\n",
        "                                         val_result[ol_index]))\n",
        "    ol_index += 1\n",
        "\n",
        "# 4. 評価\n",
        "print(\"--\\n outer loopの平均結果 ：{}\\n--\".format(val_result.mean(axis=0)))\n",
        "# 出力すると3番目のハイパーパラメータ C=100が良いと分かる\n",
        "\n",
        "# 5. テストデータで性能確認\n",
        "clf_pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                     ('logistic', LogisticRegression(C=100))])\n",
        "il_index = 0  # inner-loopのindex\n",
        "test_result = np.zeros(5*4)  # outer_loop数×inner_loop数\n",
        "\n",
        "# outer loop\n",
        "for train_val_index, test_index in outer_loop.split(X):\n",
        "    X_train_val, X_test = X[train_val_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_val_index], y[test_index]\n",
        "\n",
        "    # inner loop\n",
        "    for train_index, val_index in inner_loop.split(X_train_val):\n",
        "        X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
        "        y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
        "\n",
        "        clf_pipe.fit(X_train, y_train)  # trainで学習し\n",
        "        test_result[il_index] = clf_pipe.score(X_test, y_test)  # testの正解率を求める\n",
        "\n",
        "        print(\" inner loopの結果その{}：{}\".format(il_index +\n",
        "                                             1, test_result[il_index]))\n",
        "        il_index += 1\n",
        "\n",
        "print(\"--\\n テストデータの平均正解率：{}\".format(test_result.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}